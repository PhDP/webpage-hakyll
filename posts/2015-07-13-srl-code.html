---
title: A gentle introduction to statistical relational learning: maths, code, and examples
tags: machine learning, artificial intelligence, manticore
---

<p>Statistical relational learning is a branch of machine learning (A.I.)
mixing ideas from probability theory and logic. I'll write another post later
to explain the motivation and a bit of history of this fascinating branch of
study but here I want to focus on a concrete example, with detailed
maths and real code.</p>

<p>The approach to statistical relational learning explained here is called
Markov logic network (MLN), <a
href='https://homes.cs.washington.edu/~pedrod/kbmn.pdf'>discovered in 2006 by
Richardson and Domingo.</a> Their paper has a nice simple example of MLN
applied to the relationship between smoking and cancer. However, it's a bit
hard to follow unless you understand logic and probabilistic graphical models
well, so I'll go into much more details here. I'll also show an interactive
session with <a href='https://github.com/PhDP/Manticore'>Manticore</a>, a small
implementation I wrote for interacting with models.</p>

<p>A Markov logic network is simply a set of formulas written in first-order
logic, each associated with a weight. We'll use this for our examples:</p>

<table style='width: 80%'>
  <tr>
    <th>Statement</th>
    <th>Weight</th>
  </tr>
  <tr>
    <td>Smoking causes cancers</td>
    <td align='center'>1.1</td>
  </tr>
  <tr>
    <td>If two people are friends and one smokes, then so does the other</td>
    <td align='center'>1.5</td>
  </tr>
</table>

<p>Using a more formal representation for logic, we'll get:</p>

\[\forall x: Smoking(x) \Rightarrow Cancer(x), 1.5;\]
\[\forall x, y: Friend(x, y) \land Smoking(x) \Rightarrow Smoking(y), 1.1;\]

<p<a href='https://en.wikipedia.org/wiki/List_of_logic_symbols'>Wikipedia has a
  nice page on the various symbols</a>, but we'll only a few: \(\forall\) is "for all", \(\land\) is "and", and \(\Rightarrow\) is "implies". Then we have
the weight: the higher it is, the stronger the statement.</p>

<p>The grand idea here is that, in pure logic, a world is false if it violates
a single formula, but in statistical relational learning, a world is less
likely if it violates formulas, especially if it violates formula with a high
weight. is the log odds between a world where F is true and a world where F is
false. It has important advances on probabilistic approaches too: a first-order
logic formula is simple to understand and interpret, it can be manipulated by
humans in computers in ways a naked probabilistic model can't.</p>

<h2>Inference in Markov logic</h2>

<p>Where's our network? It's called a Markov logic network, but all we got
is a set of weighted first-order logic formulas. While I do suggest you spread
riots and chaos in anger, there's actually a simple explanation. A Markov
logic network is a template for Markov networks. Take the formula:</p>

\[\forall x: Smoking(x) \Rightarrow Cancer(x), 1.5;\]

<p><i>x</i> is a variable, and to get a concrete model for inference from this
template, we need to constraints the MLN with a set of constants. So in essence:</p>

\[\mbox{MLN + Constants} \rightarrow \mbox{Markov Network}\]

<p>Let's say we are interested smoking/cancer for Anna, Bob, Charlotte, Dominique,
we can apply these constants to the formula to get a set of ground formulas.
The term ground means the variables are replaced by constants, that is, concrete
objects. For example in mathematics you probably encountered first-order logic formulas like:</p>

\[\forall x: Add(x, 0) = 0\]

<p>For this formula, we can have grounding by replacing x with integers</p>

\[Add(47, 0) = 0\]
\[Add(1729, 0) = 0\]

<p>Similarly, applying the set of constants \(\{Elaine, Jerry, George\}\) to our first formula yields a set of ground formulas:</p>

\[Smoking(Elaine) \Rightarrow Cancer(Elaine), 1.5;\]
\[Smoking(Jerry) \Rightarrow Cancer(Jerry), 1.5;\]
\[Smoking(George) \Rightarrow Cancer(George), 1.5;\]

<p>We could do the same thing with the other formula, but now it has two
variables:</p>

\[Friend(Elaine, Elaine) \land Smoking(Elaine) \Rightarrow Smoking(Elaine), 1.1;\]
\[Friend(Elaine, Jerry) \land Smoking(Elaine) \Rightarrow Smoking(Jerry), 1.1;\]
\[Friend(Elaine, George) \land Smoking(Elaine) \Rightarrow Smoking(George), 1.1;\]
\[Friend(Jerry, Elaine) \land Smoking(Jerry) \Rightarrow Smoking(Elaine), 1.1;\]
\[Friend(Jerry, Jerry) \land Smoking(Jerry) \Rightarrow Smoking(Jerry), 1.1;\]
\[Friend(Jerry, George) \land Smoking(Jerry) \Rightarrow Smoking(George), 1.1;\]
\[Friend(George, Elaine) \land Smoking(George) \Rightarrow Smoking(Elaine), 1.1;\]
\[Friend(George, Jerry) \land Smoking(George) \Rightarrow Smoking(Jerry), 1.1;\]
\[Friend(George, George) \land Smoking(George) \Rightarrow Smoking(George), 1.1;\]

<p>From the groundings of the two formulas, we get a set of predicates:</p>

\[\{Smoking(Elaine), Smoking(Jerry), Smoking(George), Cancer(Elaine),\]

\[Cancer(Jerry), Cancer(George), Friend(Elaine, Elaine), Friend(Elaine, Jerry),\]

\[Friend(Elaine, George), Friend(Jerry, Elaine), Friend(Jerry, Jerry),\]

\[Friend(Jerry, George), Friend(George, Elaine),\]

\[Friend(George, Jerry), Friend(Jerry, George)\}\]

<p>We now have the basic blocs for inference. Of course, we could generate a
completely different set of ground formulas and ground predicates if we
applied, say, the constants \(\{William, Anastasia, Kara, Saul, Karl, Tory,
Felix, Laura\}\), or any number of objects we're interested in. Also, we
don't need to have full data on all predicates, I'll show examples where we
have no information at all.</p>

<h2>From predicates and formulas to Markov network</h2>

<p>Hey, we still don't have our network! To finally get our network, we'll
create one node for each ground predicate, and link all nodes that are in the
same formula. We our example with the constants \(\{Elaine, jerry, George\}\),
we get the following Markov network:</p>

<div class="imagecenter">
  <img src="../images/ground_seinfeld.png" alt="ground network"/>
</div>

<p>For example, since we have</p>

\[Friend(Elaine, Elaine) \land Smoking(Elaine) \Rightarrow Smoking(Elaine), 1.1;\]

<p>These nodes are linked in the network:</p>

<div class="imagecenter">
  <img src="../images/ground_seinfeld_hl.png" alt="ground network hl"/>
</div>

<p>To compute probabilities, we use the equation:</p>

\[P(X = x) = \frac{1}{Z}\prod \]

<p>If it can be a bit abstract, let's do the maths for the marginal probability:</p>

\[P(Cancer(Jerry))\]

\[P(Cancer(Jerry)) = \frac{P(Cancer(Jerry), Smoking(Elaine))}{Smoking(Elaine)}\]

<h2>Code</h2>

<p>Right now, it performs only exact inference, which is useful for tests...
but it does not scale (the Markov networks generated by Markov logic are
humongous). It'll be enough for exploring a model.</p>

<p>First, import the Markov logic network module:</p>

<pre><code class="haskell">ghci> import qualified Manticore.MarkovLogic as ML</code></pre>

<p>The most straighforward way to build a Markov logic network is with
<i>fromStrings</i>. This function takes an array of strings, each of which must
be a valid first-order logic formula followed (or preceded) by a number (the
weight of the formula). In this case we have:</p>

<pre><code class="haskell">ghci> let mln = ML.fromStrings ["∀x Smoking(x) ⇒ Cancer(x) 1.5", "∀x∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y) 1.1"]</code></pre>

<p>The strings were copy-pasted from Richardson and Domingos' paper, but the
parsers is flexible and will accept a keyboard-friendly form too:</p>

<pre><code class="haskell">ghci> ML.fromStrings ["1.5 forall x Smoking(x) implies Cancer(x)", "1.1 forall x, y Friend(x, y) and Smoking(x) implies Smoking(y)"]</code></pre>

<p>We can use <i>fmtMLN</i> function to print the Markov logic
network:</p>

<pre><code class="haskell">ghci> putStrLn (fmtMLN mln)
1.5                     ∀x Smoking(x) ⇒ Cancer(x)
1.1                     ∀x ∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y)</code></pre>

<p>A Markov logic network is a template for Markov networks. To get a Markov
network, we need to apply a set of constant to the Markov logic networks
Here, we will create only two constants:</p>

<pre><code class="haskell">ghci> let cs = ["Anna", "Bob"]</code></pre>

<p>Then, we can query the network, say, what is the probability that Anna has
cancer?</p>

<pre><code class="haskell">ghci> ML.ask cs mln "P(Cancer(Anna))"
Just 0.6133819604540808</code></pre>

<p>The function <i>ask</i> takes a Markov logic network, a list
of terms (represented as a list of strings), and a string query. It will return
Just P, with P being a probability in the [0.0, 1.0] range, or Nothing if the
parser fails to read the query. To make the process a bit easier we'll create
a function ask that have already the mln and terms supplied:</p>

<pre><code class="haskell">ghci> let ask = MLN.ask mln cs</code></pre>

Then we can ask queries with this function:

<pre><code class="haskell">ghci> ask "P(Cancer(Anna) and Cancer(Bob))"
Just 0.38061259085226223</code></pre>

<pre><code class="haskell">ghci> ask "P(Cancer(Anna) | Smoking(Bob))"
Just 0.6519697695221907</code></pre>

<pre><code class="haskell">ghci> ask "P(Cancer(Anna) | Smoking(Bob), Friend(Bob, Anna))"
Just 0.7056438194691147</code></pre>

We could write \"Cancer(Anna) = True\", but the parser assumes all predicates
are true if they are not assigned to a value. If we can to say something is
false, say: Anna is not smoking, we could write \"Smoking(Anna) = False\" or
the shorter \"!Smoking(Anna)\"

<pre><code class="haskell">ghci> ask "P(Cancer(Anna) | !Smoking(Anna), Smoking(Bob), Friend(Bob, Anna))"
Just 0.49999999999999994

ghci> ask "P(Cancer(Anna) | !Smoking(Anna), !Smoking(Bob), !Friend(Bob, Anna))"
Just 0.5000000000000002</code></pre>

We can add a logic formula to the network with the 'Manticore.MarkovLogic.tell'
function. Note that 'Manticore.MarkovLogic.tell' takes a string (just like
'Manticore.MarkovLogic.fromStrings' takes a list of strings) and will return
a new Markov logic network with the formula added. Let's say we want to add
a rule that /friends of friends are friends/, we could add this rule with a
weight of 1.0 with:

<pre><code class="haskell">ghci> let mln2 = tell "1.0 A.x,y,z Friend(x, y) and Friend(y, z) => Friend(x, z)" mln
ghci> putStrLn (fmtMLN mln2)
1.5                     ∀x Smoking(x) ⇒ Cancer(x)
1.0                     ∀x ∀y ∀z Friend(x, y) ∧ Friend(y, z) ⇒ Friend(x, z)
1.1                     ∀x ∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y)</code></pre>

This time we'll ask queries with this network using four objects: Anna, Bob,
Charlotte, Dominique, again creating a shortcut function ask2 to avoid always
providing the same arguments:

<pre><code class="haskell">ghci> let cs2 = ["Anna", "Bob", "Charlotte"]
ghci> let ask2 = ML.ask cs2 mln2</code></pre>

<pre><code class="haskell">ghci> ask2 "P(Cancer(Anna))"
Just 0.6093306813995714
ghci> ask2 "P(Cancer(Anna) | Smoking(Bob) and Friend(Bob, Charlotte))"
Just 0.6504904438065744
ghci> ask2 "P(Cancer(Anna) | Smoking(Bob))"
Just 0.6399247839775043
ghci> ask2 "P(Cancer(Anna) | Smoking(Bob) and Friend(Bob, Charlotte) and Friend(Charlotte, Anna))"
Just 0.7070401384366385
ghci> ask2 "P(Cancer(Anna) | Smoking(Bob) and Friend(Bob, Charlotte) and !Friend(Charlotte, Anna))"
Just 0.6329610969479669
ghci> ask2 "P(Cancer(Anna) | Smoking(Bob) and Friend(Bob, Charlotte) and Friend(Charlotte, Anna) and !Smoking(Anna))"
Just 0.4999999999999977
ghci> ask2 "P(Cancer(Anna) | !Smoking(Anna))"
Just 0.49999999999999856</code></pre>

\[\forall Friend(x, y) \iff Friend(y, x), w;\]

